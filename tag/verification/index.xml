<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>verification | Data Shenanigans</title>
    <link>https://davzim.github.io/tag/verification/</link>
      <atom:link href="https://davzim.github.io/tag/verification/index.xml" rel="self" type="application/rss+xml" />
    <description>verification</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>2023</copyright><lastBuildDate>Thu, 13 Jul 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://davzim.github.io/images/logo.svg</url>
      <title>verification</title>
      <link>https://davzim.github.io/tag/verification/</link>
    </image>
    
    <item>
      <title>Introducing dataverifyr: A Lightweight, Flexible, and Fast Data Validation Package that Can Handle All Sizes of Data </title>
      <link>https://davzim.github.io/blog/2023-07-13-dataverifyr/</link>
      <pubDate>Thu, 13 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://davzim.github.io/blog/2023-07-13-dataverifyr/</guid>
      <description>


&lt;p&gt;In every data project, there should be a check that the data actually looks like what you expect it to look like.
This can be as simple as &lt;code&gt;stopifnot(all(data$values &amp;gt; 0))&lt;/code&gt;, but as with everything “simple”, you typically want to have some additional features, such as cleaner error messages, rules separated from your R script (eg in a yaml file), result visualization, and last but least, a library that does this as fast as possible.
The last bit is especially important when you have the data in a database or as an &lt;code&gt;arrow&lt;/code&gt; &lt;code&gt;.parquet&lt;/code&gt; file, due to its size or complexity.&lt;/p&gt;
&lt;p&gt;The newly released &lt;a href=&#34;https://github.com/DavZim/dataverifyr/&#34;&gt;&lt;code&gt;dataverifyr&lt;/code&gt;&lt;/a&gt; package (on &lt;a href=&#34;https://cran.r-project.org/package=dataverifyr&#34;&gt;CRAN&lt;/a&gt;) allows you to do exactly that: write rules in a yaml file, load the rules, check if the rules where matched and filter for data points that do not conform to the rules; all while respecting your data framework: &lt;code&gt;data.table&lt;/code&gt;, &lt;code&gt;dplyr&lt;/code&gt;, &lt;code&gt;arrow&lt;/code&gt;, &lt;code&gt;duckdb&lt;/code&gt;, or other &lt;code&gt;DBI&lt;/code&gt;-compliant databases.&lt;/p&gt;
&lt;p&gt;The following is an excerpt of the Readme of ´dataverifyr` that highlights how to use the package.&lt;/p&gt;
&lt;div id=&#34;larger-example-using-the-arrow-backend&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Larger Example using the &lt;code&gt;arrow&lt;/code&gt; backend&lt;/h2&gt;
&lt;p&gt;For a more involved example, using a different backend, let’s say we
have a larger dataset of taxi trips from NY (see also the official
&lt;a href=&#34;https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page&#34;&gt;source of the
data&lt;/a&gt;),
that we have saved as a local arrow dataset (using parquet as a data
format), where we want to make sure that some variables are in-line with
our expectations/rules.&lt;/p&gt;
&lt;div id=&#34;download-and-prepare-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;1 Download and Prepare Data&lt;/h3&gt;
&lt;p&gt;First we prepare the data by downloading it and writing the dataset to
&lt;code&gt;.parquet&lt;/code&gt; files. This needs to be done only once and is shown for
reproducibility reasons only, the actual &lt;code&gt;dataverifyr&lt;/code&gt; code is shown
below the next block&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(arrow)
url &amp;lt;- &amp;quot;https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2018-01.parquet&amp;quot;
file &amp;lt;- &amp;quot;yellow_tripdata_2018-01.parquet&amp;quot;
if (!file.exists(file)) download.file(url, file, method = &amp;quot;curl&amp;quot;)
file.size(file) / 1e6 # in MB
#&amp;gt; [1] 123.6685

# quick check of the filesize
d &amp;lt;- read_parquet(file)
dim(d)
#&amp;gt; [1] 8760687      19
names(d)
#&amp;gt;  [1] &amp;quot;VendorID&amp;quot;              &amp;quot;tpep_pickup_datetime&amp;quot;  &amp;quot;tpep_dropoff_datetime&amp;quot; &amp;quot;passenger_count&amp;quot;      
#&amp;gt;  [5] &amp;quot;trip_distance&amp;quot;         &amp;quot;RatecodeID&amp;quot;            &amp;quot;store_and_fwd_flag&amp;quot;    &amp;quot;PULocationID&amp;quot;         
#&amp;gt;  [9] &amp;quot;DOLocationID&amp;quot;          &amp;quot;payment_type&amp;quot;          &amp;quot;fare_amount&amp;quot;           &amp;quot;extra&amp;quot;                
#&amp;gt; [13] &amp;quot;mta_tax&amp;quot;               &amp;quot;tip_amount&amp;quot;            &amp;quot;tolls_amount&amp;quot;          &amp;quot;improvement_surcharge&amp;quot;
#&amp;gt; [17] &amp;quot;total_amount&amp;quot;          &amp;quot;congestion_surcharge&amp;quot;  &amp;quot;airport_fee&amp;quot;

# write the dataset to disk
write_dataset(d, &amp;quot;nyc-taxi-data&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;create-rules-in-yaml&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;2 Create Rules in &lt;code&gt;yaml&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Next, we can create some rules that we will use to check our data. As we
saw earlier, we can create the rules in R using the &lt;code&gt;rule()&lt;/code&gt; and
&lt;code&gt;ruleset()&lt;/code&gt; functions, there is however, the (in my opinion) preferred
option to separate the code from the rules by writing the rules in a
separate yaml file and reading them into R.&lt;/p&gt;
&lt;p&gt;First we display the hand-written contents of the &lt;code&gt;nyc_data_rules.yaml&lt;/code&gt;
file.&lt;/p&gt;
&lt;pre class=&#34;yaml&#34;&gt;&lt;code&gt;- name: &amp;#39;Rule for: passenger_count&amp;#39;
  expr: passenger_count &amp;gt;= 0 &amp;amp; passenger_count &amp;lt;= 10
  allow_na: no
  negate: no
  index: 1
- name: &amp;#39;Rule for: trip_distance&amp;#39;
  expr: trip_distance &amp;gt;= 0 &amp;amp; trip_distance &amp;lt;= 1000
  allow_na: no
  negate: no
  index: 2
- name: &amp;#39;Rule for: payment_type&amp;#39;
  expr: payment_type %in% c(0, 1, 2, 3, 4)
  allow_na: no
  negate: no
  index: 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, we can load, display, and finally check the rules against the data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rules &amp;lt;- read_rules(&amp;quot;nyc_data_rules.yaml&amp;quot;)
rules
#&amp;gt; &amp;lt;Verification Ruleset with 3 elements&amp;gt;
#&amp;gt;   [1] &amp;#39;Rule for: passenger_count&amp;#39; matching `passenger_count &amp;gt;= 0 &amp;amp; passenger_count &amp;lt;= 10` (allow_na: FALSE)
#&amp;gt;   [2] &amp;#39;Rule for: trip_distance&amp;#39; matching `trip_distance &amp;gt;= 0 &amp;amp; trip_distance &amp;lt;= 1000` (allow_na: FALSE)
#&amp;gt;   [3] &amp;#39;Rule for: payment_type&amp;#39; matching `payment_type %in% c(0, 1, 2, 3, 4)` (allow_na: FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;verify-that-the-data-matches-the-given-rules&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;3 Verify that the Data matches the given Rules&lt;/h3&gt;
&lt;p&gt;Now we can check if the data follows our rules or if we have unexpected
data points:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# open the dataset 
ds &amp;lt;- open_dataset(&amp;quot;nyc-taxi-data/&amp;quot;)

# perform the data validation check
res &amp;lt;- check_data(ds, rules)
res
#&amp;gt; # A tibble: 3 × 10
#&amp;gt;   name                      expr              allow…¹ negate   tests    pass  fail warn  error time 
#&amp;gt;   &amp;lt;chr&amp;gt;                     &amp;lt;chr&amp;gt;             &amp;lt;lgl&amp;gt;   &amp;lt;lgl&amp;gt;    &amp;lt;int&amp;gt;   &amp;lt;int&amp;gt; &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;drt&amp;gt;
#&amp;gt; 1 Rule for: passenger_count passenger_count … FALSE   FALSE  8760687 8760687     0 &amp;quot;&amp;quot;    &amp;quot;&amp;quot;    0.56…
#&amp;gt; 2 Rule for: trip_distance   trip_distance &amp;gt;=… FALSE   FALSE  8760687 8760686     1 &amp;quot;&amp;quot;    &amp;quot;&amp;quot;    0.43…
#&amp;gt; 3 Rule for: payment_type    payment_type %in… FALSE   FALSE  8760687 8760687     0 &amp;quot;&amp;quot;    &amp;quot;&amp;quot;    0.42…
#&amp;gt; # … with abbreviated variable name ¹​allow_na

plot_res(res)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;README-taxi3-1.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Using the power of &lt;code&gt;arrow&lt;/code&gt;, we were able to scan 8+mln observations for
three rules in about 1.5 seconds (YMMV). As we can see from the results,
there is one unexpected value, lets quickly investigate using the
&lt;code&gt;filter_fails()&lt;/code&gt; function, which filters a dataset for the failed rule
matches&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;res |&amp;gt;
  filter_fails(ds) |&amp;gt; 
  # only select a couple of variables for brevity
  dplyr::select(tpep_pickup_datetime, tpep_dropoff_datetime, trip_distance)
#&amp;gt; # A tibble: 1 × 3
#&amp;gt;   tpep_pickup_datetime tpep_dropoff_datetime trip_distance
#&amp;gt;   &amp;lt;dttm&amp;gt;               &amp;lt;dttm&amp;gt;                        &amp;lt;dbl&amp;gt;
#&amp;gt; 1 2018-01-30 12:41:02  2018-01-30 12:42:09         189484.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we can see, this is probably a data error (a trip distance of 190k
miles in 1 minute seems - ehm stellar…).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;using-a-dbi-backend&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using a &lt;code&gt;DBI&lt;/code&gt; Backend&lt;/h2&gt;
&lt;p&gt;If you have a &lt;code&gt;SQLite&lt;/code&gt; or &lt;code&gt;duckdb&lt;/code&gt; database, you can use the package
like this&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(DBI)
library(dplyr)

# connect to a duckdb database
con &amp;lt;- dbConnect(duckdb::duckdb(&amp;quot;duckdb-database.duckdb&amp;quot;))
# for demo purposes write the data once
dbWriteTable(con, &amp;quot;mtcars&amp;quot;, mtcars)

# create a tbl connection, which can be used in the checks
tbl &amp;lt;- tbl(con, &amp;quot;mtcars&amp;quot;)

# create rules
rules &amp;lt;- ruleset(
  rule(mpg &amp;gt; 10 &amp;amp; mpg &amp;lt; 30),
  rule(cyl %in% c(4, 8)),
  rule(vs %in% c(0, 1), allow_na = TRUE)
)

# check rules
res &amp;lt;- check_data(tbl, rules)
res
#&amp;gt; # A tibble: 3 × 10
#&amp;gt;   name          expr                allow_na negate tests  pass  fail warn  error time          
#&amp;gt;   &amp;lt;chr&amp;gt;         &amp;lt;chr&amp;gt;               &amp;lt;lgl&amp;gt;    &amp;lt;lgl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;drtn&amp;gt;        
#&amp;gt; 1 Rule for: mpg mpg &amp;gt; 10 &amp;amp; mpg &amp;lt; 30 FALSE    FALSE     32    28     4 &amp;quot;&amp;quot;    &amp;quot;&amp;quot;    3.5227668 secs
#&amp;gt; 2 Rule for: cyl cyl %in% c(4, 8)    FALSE    FALSE     32    25     7 &amp;quot;&amp;quot;    &amp;quot;&amp;quot;    0.2015200 secs
#&amp;gt; 3 Rule for: vs  vs %in% c(0, 1)     TRUE     FALSE     32    32     0 &amp;quot;&amp;quot;    &amp;quot;&amp;quot;    0.1898661 secs

filter_fails(res, tbl, per_rule = TRUE)
#&amp;gt; $`mpg &amp;gt; 10 &amp;amp; mpg &amp;lt; 30`
#&amp;gt; # A tibble: 4 × 11
#&amp;gt;     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb
#&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
#&amp;gt; 1  32.4     4  78.7    66  4.08 2.2   19.47     1     1     4     1
#&amp;gt; 2  30.4     4  75.7    52  4.93 1.615 18.52     1     1     4     2
#&amp;gt; 3  33.9     4  71.1    65  4.22 1.835 19.9      1     1     4     1
#&amp;gt; 4  30.4     4  95.1   113  3.77 1.513 16.9      1     1     5     2
#&amp;gt; 
#&amp;gt; $`cyl %in% c(4, 8)`
#&amp;gt; # A tibble: 7 × 11
#&amp;gt;     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb
#&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
#&amp;gt; 1  21       6 160     110  3.9  2.62  16.46     0     1     4     4
#&amp;gt; 2  21       6 160     110  3.9  2.875 17.02     0     1     4     4
#&amp;gt; 3  21.4     6 258     110  3.08 3.215 19.44     1     0     3     1
#&amp;gt; 4  18.1     6 225     105  2.76 3.46  20.22     1     0     3     1
#&amp;gt; 5  19.2     6 167.6   123  3.92 3.44  18.3      1     0     4     4
#&amp;gt; 6  17.8     6 167.6   123  3.92 3.44  18.9      1     0     4     4
#&amp;gt; 7  19.7     6 145     175  3.62 2.77  15.5      0     1     5     6

# lastly disconnect from the database again
dbDisconnect(con, shutdown = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
